{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a5d797",
   "metadata": {},
   "source": [
    "# Big Data Project\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. Loading datasets\n",
    "2. Data cleaning and feature selection\n",
    "3. Exploratory Data Analysis\n",
    "4. Hypothesis I: Football matches\n",
    "5. Hypothesis II:\n",
    "6. Hypothesis III:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0685404",
   "metadata": {},
   "source": [
    "## Packages\n",
    "Importing all necessary packages to run the notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd89783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import regex as re\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# packages for web scraping\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "\n",
    "#packages for data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e4867",
   "metadata": {},
   "source": [
    "## Directory navigation and creation\n",
    "Creating pathlib.Path objects for cross-platform navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e1de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Path object for current working directory\n",
    "directory = Path('./')\n",
    "# creating Path object for additional data directory\n",
    "additional_directory = directory / 'additional_data'\n",
    "# create new directory for additional data\n",
    "Path(additional_directory).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "048f565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/vehicles2019.csv\n",
      "data/accidents2019.csv\n",
      "data/casualties2019.csv\n"
     ]
    }
   ],
   "source": [
    "# defining the directory to original data\n",
    "directory = Path('./data/')\n",
    "additional_directory = Path('./additional_data')\n",
    "\n",
    "# list the .csv files for the project\n",
    "for file in directory.glob('*.csv'):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c4c98",
   "metadata": {},
   "source": [
    "## Reading datasets\n",
    "Reading in the original three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207da135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accident_index</th>\n",
       "      <th>location_easting_osgr</th>\n",
       "      <th>location_northing_osgr</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>police_force</th>\n",
       "      <th>accident_severity</th>\n",
       "      <th>number_of_vehicles</th>\n",
       "      <th>number_of_casualties</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>pedestrian_crossing-human_control</th>\n",
       "      <th>pedestrian_crossing-physical_facilities</th>\n",
       "      <th>light_conditions</th>\n",
       "      <th>weather_conditions</th>\n",
       "      <th>road_surface_conditions</th>\n",
       "      <th>special_conditions_at_site</th>\n",
       "      <th>carriageway_hazards</th>\n",
       "      <th>urban_or_rural_area</th>\n",
       "      <th>did_police_officer_attend_scene_of_accident</th>\n",
       "      <th>lsoa_of_accident_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019010128300</td>\n",
       "      <td>528218.0</td>\n",
       "      <td>180407.0</td>\n",
       "      <td>-0.153842</td>\n",
       "      <td>51.508057</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18/02/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>E01004762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019010152270</td>\n",
       "      <td>530219.0</td>\n",
       "      <td>172463.0</td>\n",
       "      <td>-0.127949</td>\n",
       "      <td>51.436208</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>E01003117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019010155191</td>\n",
       "      <td>530222.0</td>\n",
       "      <td>182543.0</td>\n",
       "      <td>-0.124193</td>\n",
       "      <td>51.526795</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E01000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019010155192</td>\n",
       "      <td>525531.0</td>\n",
       "      <td>184605.0</td>\n",
       "      <td>-0.191044</td>\n",
       "      <td>51.546387</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E01000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019010155194</td>\n",
       "      <td>524920.0</td>\n",
       "      <td>184004.0</td>\n",
       "      <td>-0.200064</td>\n",
       "      <td>51.541121</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E01000546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  accident_index  location_easting_osgr  location_northing_osgr  longitude  \\\n",
       "0  2019010128300               528218.0                180407.0  -0.153842   \n",
       "1  2019010152270               530219.0                172463.0  -0.127949   \n",
       "2  2019010155191               530222.0                182543.0  -0.124193   \n",
       "3  2019010155192               525531.0                184605.0  -0.191044   \n",
       "4  2019010155194               524920.0                184004.0  -0.200064   \n",
       "\n",
       "    latitude  police_force  accident_severity  number_of_vehicles  \\\n",
       "0  51.508057             1                  3                   2   \n",
       "1  51.436208             1                  3                   2   \n",
       "2  51.526795             1                  3                   2   \n",
       "3  51.546387             1                  2                   1   \n",
       "4  51.541121             1                  3                   2   \n",
       "\n",
       "   number_of_casualties        date  ...  pedestrian_crossing-human_control  \\\n",
       "0                     3  18/02/2019  ...                                  0   \n",
       "1                     1  15/01/2019  ...                                 -1   \n",
       "2                     1  01/01/2019  ...                                  0   \n",
       "3                     1  01/01/2019  ...                                  0   \n",
       "4                     2  01/01/2019  ...                                  0   \n",
       "\n",
       "  pedestrian_crossing-physical_facilities  light_conditions  \\\n",
       "0                                       5                 1   \n",
       "1                                      -1                 4   \n",
       "2                                       0                 4   \n",
       "3                                       0                 4   \n",
       "4                                       0                 4   \n",
       "\n",
       "  weather_conditions  road_surface_conditions  special_conditions_at_site  \\\n",
       "0                  1                        1                           0   \n",
       "1                  1                        1                           0   \n",
       "2                  1                        1                           0   \n",
       "3                  1                        1                           0   \n",
       "4                  1                        1                           0   \n",
       "\n",
       "   carriageway_hazards  urban_or_rural_area  \\\n",
       "0                    0                    1   \n",
       "1                    0                    1   \n",
       "2                    0                    1   \n",
       "3                    0                    1   \n",
       "4                    0                    1   \n",
       "\n",
       "   did_police_officer_attend_scene_of_accident  lsoa_of_accident_location  \n",
       "0                                            3                  E01004762  \n",
       "1                                            3                  E01003117  \n",
       "2                                            1                  E01000943  \n",
       "3                                            1                  E01000973  \n",
       "4                                            1                  E01000546  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in .csv files to dataframes\n",
    "vehicles = pd.read_csv(directory / 'vehicles2019.csv', dtype={'Accident_Index': str})\n",
    "casualties = pd.read_csv(directory / 'casualties2019.csv', dtype={'Accident_Index': str})\n",
    "accidents = pd.read_csv(directory / 'accidents2019.csv', dtype={'Accident_Index': str,\n",
    "                                                                'LSOA_of_Accident_Location': str})\n",
    "\n",
    "# convert column names to lowercase for ease of indexing\n",
    "def lower_columns(df):\n",
    "    \"\"\"\n",
    "    Defintion:\n",
    "        convert column names to lower case\n",
    "    \"\"\"\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    \n",
    "# converting all column names to lower case\n",
    "lower_columns(vehicles)\n",
    "lower_columns(casualties)\n",
    "lower_columns(accidents)\n",
    "\n",
    "accidents.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07326ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accident_index                                    0\n",
       "location_easting_osgr                            28\n",
       "location_northing_osgr                           28\n",
       "longitude                                        28\n",
       "latitude                                         28\n",
       "police_force                                      0\n",
       "accident_severity                                 0\n",
       "number_of_vehicles                                0\n",
       "number_of_casualties                              0\n",
       "date                                              0\n",
       "day_of_week                                       0\n",
       "time                                             63\n",
       "local_authority_(district)                        0\n",
       "local_authority_(highway)                         0\n",
       "1st_road_class                                    0\n",
       "1st_road_number                                   0\n",
       "road_type                                         0\n",
       "speed_limit                                       0\n",
       "junction_detail                                   0\n",
       "junction_control                                  0\n",
       "2nd_road_class                                    0\n",
       "2nd_road_number                                   0\n",
       "pedestrian_crossing-human_control                 0\n",
       "pedestrian_crossing-physical_facilities           0\n",
       "light_conditions                                  0\n",
       "weather_conditions                                0\n",
       "road_surface_conditions                           0\n",
       "special_conditions_at_site                        0\n",
       "carriageway_hazards                               0\n",
       "urban_or_rural_area                               0\n",
       "did_police_officer_attend_scene_of_accident       0\n",
       "lsoa_of_accident_location                      5714\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking features with NaN values\n",
    "accidents.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab621bb",
   "metadata": {},
   "source": [
    "## Data Cleaning and Feature Creation\n",
    "1. latitude and longitude imputation\n",
    "    \n",
    "    \n",
    "    SOURCE: https://simplemaps.com/data/gb-cities\n",
    "    \n",
    "2. Datetime formatting\n",
    "\n",
    "    SOURCE: https://www.sunrise-and-sunset.com/en/sun/united-kingdom/london/2019/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9a938d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the local_authority.csv file of local_athority data that came with the original accident data\n",
    "local_authorities = pd.read_csv(additional_directory / 'local_authority.csv')\n",
    "local_authorities.columns = ['local_authority_(district)', 'district']\n",
    "\n",
    "# merge the accidents dataframe with the local_authorities dataframe on 'local_authority_(district)'\n",
    "accidents = pd.merge(accidents, local_authorities, on=['local_authority_(district)'])\n",
    "\n",
    "accidents[['longitude', 'latitude', 'local_authority_(district)', 'district']]\n",
    "accidents.district = accidents.district.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e91aaa99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude_new</th>\n",
       "      <th>longitude_new</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.5072</td>\n",
       "      <td>-0.1275</td>\n",
       "      <td>london, city of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.4800</td>\n",
       "      <td>-1.9025</td>\n",
       "      <td>birmingham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.4794</td>\n",
       "      <td>-2.2453</td>\n",
       "      <td>manchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.7997</td>\n",
       "      <td>-1.5492</td>\n",
       "      <td>leeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.0077</td>\n",
       "      <td>-1.6578</td>\n",
       "      <td>newcastle upon tyne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>53.4960</td>\n",
       "      <td>-1.4120</td>\n",
       "      <td>rotherham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>57.2670</td>\n",
       "      <td>-2.1920</td>\n",
       "      <td>aberdeenshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>51.6116</td>\n",
       "      <td>-3.5842</td>\n",
       "      <td>bridgend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>51.1536</td>\n",
       "      <td>1.3714</td>\n",
       "      <td>kent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>52.0500</td>\n",
       "      <td>-0.6940</td>\n",
       "      <td>milton keynes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2680 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude_new  longitude_new             district\n",
       "0          51.5072        -0.1275      london, city of\n",
       "1          52.4800        -1.9025           birmingham\n",
       "2          53.4794        -2.2453           manchester\n",
       "3          53.7997        -1.5492                leeds\n",
       "4          55.0077        -1.6578  newcastle upon tyne\n",
       "...            ...            ...                  ...\n",
       "2675       53.4960        -1.4120            rotherham\n",
       "2676       57.2670        -2.1920        aberdeenshire\n",
       "2677       51.6116        -3.5842             bridgend\n",
       "2678       51.1536         1.3714                 kent\n",
       "2679       52.0500        -0.6940        milton keynes\n",
       "\n",
       "[2680 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the latitude, longitude and admin_name columns of the city_coords.csv file\n",
    "cities = pd.read_csv(additional_directory / 'city_coords.csv', usecols=['lat', 'lng', 'admin_name'])\n",
    "cities.columns = ['latitude_new', 'longitude_new', 'district']\n",
    "cities.district = cities.district.str.lower()\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be2efe9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Districts with missing coordinate data: {'wirral', 'flintshire', 'harrogate', 'ryedale', 'scarborough', 'north east lincolnshire', 'wakefield', 'hambleton', 'west dorset', 'wigan', 'powys', 'warrington', 'cheshire east', 'liverpool', 'adur', 'rugby', 'cardiff', 'medway', 'cheshire west and chester', 'selby'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hambleton                    4\n",
       "harrogate                    3\n",
       "selby                        3\n",
       "ryedale                      2\n",
       "north east lincolnshire      1\n",
       "cardiff                      1\n",
       "flintshire                   1\n",
       "west dorset                  1\n",
       "adur                         1\n",
       "medway                       1\n",
       "rugby                        1\n",
       "wigan                        1\n",
       "wakefield                    1\n",
       "wirral                       1\n",
       "scarborough                  1\n",
       "warrington                   1\n",
       "cheshire west and chester    1\n",
       "cheshire east                1\n",
       "liverpool                    1\n",
       "powys                        1\n",
       "Name: district, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the 'district' of instances with missing coordinate data\n",
    "missing_districts = accidents[accidents.longitude.isnull()]['district']\n",
    "print(f\"Districts with missing coordinate data: {set(missing_districts)}\")\n",
    "len(missing_districts)\n",
    "missing_districts.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6dee37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adur',\n",
       " 'hambleton',\n",
       " 'harrogate',\n",
       " 'rugby',\n",
       " 'ryedale',\n",
       " 'scarborough',\n",
       " 'selby',\n",
       " 'west dorset'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the 'districts' with missing coordinate data in our data set that are not in the city_coords.csv file\n",
    "set(missing_districts) - set(cities.district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f538cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2688, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually add these districts to the cities df of the city_coords.csv file\n",
    "manual_additions = pd.DataFrame(np.array([50.8348, 0.3101, 'adur', \n",
    "                                          54.2959, 1.3135, 'hambleton',\n",
    "                                          53.9921, 1.5418, 'harrogate',\n",
    "                                          52.3709, 1.2650, 'rugby',\n",
    "                                          54.1698, 0.7282, 'ryedale', \n",
    "                                          54.2831, 0.3998, 'scarborough',\n",
    "                                          53.7835, 1.0672, 'selby', \n",
    "                                          50.7755, 2.5817, 'west dorset']).reshape(-1, 3))\n",
    "manual_additions.columns = ['latitude_new', 'longitude_new', 'district']\n",
    "cities = pd.concat([cities, manual_additions], axis=0)\n",
    "\n",
    "cities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e67b73a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the 'districts' with missing coordinate data in our data set that are not in the city_coords.csv file\n",
    "set(missing_districts) - set(cities.district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ac4096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the average coordinates for locations in this district in the cities df\n",
    "cities = cities.groupby('district').median()\n",
    "\n",
    "# inner-join the accidents dataframe with the cities dataframe on the 'district' column\n",
    "accidents = accidents.merge(cities, on='district')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cc9c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the missing longitude and latitude values with the new longitude and latitude values from the cities dataframe\n",
    "accidents.loc[accidents.longitude.isnull(), 'longitude'] = accidents.loc[accidents.longitude.isnull(), 'longitude_new']\n",
    "accidents.loc[accidents.latitude.isnull(), 'latitude'] = accidents.loc[accidents.latitude.isnull(), 'latitude_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f909b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accident_index                                    0\n",
       "longitude                                         0\n",
       "latitude                                          0\n",
       "police_force                                      0\n",
       "accident_severity                                 0\n",
       "number_of_vehicles                                0\n",
       "number_of_casualties                              0\n",
       "date                                              0\n",
       "day_of_week                                       0\n",
       "time                                             59\n",
       "local_authority_(district)                        0\n",
       "local_authority_(highway)                         0\n",
       "1st_road_class                                    0\n",
       "1st_road_number                                   0\n",
       "road_type                                         0\n",
       "speed_limit                                       0\n",
       "junction_detail                                   0\n",
       "junction_control                                  0\n",
       "2nd_road_class                                    0\n",
       "2nd_road_number                                   0\n",
       "pedestrian_crossing-human_control                 0\n",
       "pedestrian_crossing-physical_facilities           0\n",
       "light_conditions                                  0\n",
       "weather_conditions                                0\n",
       "road_surface_conditions                           0\n",
       "special_conditions_at_site                        0\n",
       "carriageway_hazards                               0\n",
       "urban_or_rural_area                               0\n",
       "did_police_officer_attend_scene_of_accident       0\n",
       "lsoa_of_accident_location                      5544\n",
       "district                                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the columns used for this imputation, as well as the osgr coordinates (replicated information)\n",
    "accidents = accidents.drop(['location_easting_osgr', 'location_northing_osgr',\n",
    "                            'latitude_new', 'longitude_new'], axis=1)\n",
    "accidents.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319dc11",
   "metadata": {},
   "source": [
    "### Datetime formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fadae9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted_date dtype: datetime64[ns]\n",
      "converted_time dtype: object\n",
      "<class 'datetime.time'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>converted_date</th>\n",
       "      <th>converted_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>21:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>07:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>12:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>13:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73315</th>\n",
       "      <td>2019-05-18</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73316</th>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>08:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73317</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>15:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73318</th>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>14:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73319</th>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>12:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73320 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      converted_date converted_time\n",
       "0         2019-01-15       21:45:00\n",
       "1         2019-01-02       07:10:00\n",
       "2         2019-01-02       12:10:00\n",
       "3         2019-01-04       01:30:00\n",
       "4         2019-01-04       13:45:00\n",
       "...              ...            ...\n",
       "73315     2019-05-18       01:00:00\n",
       "73316     2019-05-30       08:46:00\n",
       "73317     2019-06-21       15:30:00\n",
       "73318     2019-06-29       14:10:00\n",
       "73319     2019-04-21       12:45:00\n",
       "\n",
       "[73320 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 'converted_date' and 'converted_column' features for manipulation of dates and times\n",
    "accidents['converted_date'] = pd.to_datetime(accidents['date'],\n",
    "                                              format='%d/%m/%Y')\n",
    "accidents['converted_time'] = pd.to_datetime(accidents['time'],\n",
    "                                             errors='coerce',\n",
    "                                             format='%H:%M').dt.time\n",
    "\n",
    "print(f'converted_date dtype: {accidents[\"converted_date\"].dtype}')\n",
    "print(f'converted_time dtype: {accidents[\"converted_time\"].dtype}')\n",
    "print(type(accidents['converted_time'][0]))\n",
    "\n",
    "accidents[['converted_date', 'converted_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11171f2f",
   "metadata": {},
   "source": [
    "So the converted_date column has a dtype of datetime64[ns]\n",
    "and the converted_time column has a dtype of object consisting of datetime.time elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f60de90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accident_index                                    0\n",
       "longitude                                         0\n",
       "latitude                                          0\n",
       "police_force                                      0\n",
       "accident_severity                                 0\n",
       "number_of_vehicles                                0\n",
       "number_of_casualties                              0\n",
       "date                                              0\n",
       "day_of_week                                       0\n",
       "time                                             59\n",
       "local_authority_(district)                        0\n",
       "local_authority_(highway)                         0\n",
       "1st_road_class                                    0\n",
       "1st_road_number                                   0\n",
       "road_type                                         0\n",
       "speed_limit                                       0\n",
       "junction_detail                                   0\n",
       "junction_control                                  0\n",
       "2nd_road_class                                    0\n",
       "2nd_road_number                                   0\n",
       "pedestrian_crossing-human_control                 0\n",
       "pedestrian_crossing-physical_facilities           0\n",
       "light_conditions                                  0\n",
       "weather_conditions                                0\n",
       "road_surface_conditions                           0\n",
       "special_conditions_at_site                        0\n",
       "carriageway_hazards                               0\n",
       "urban_or_rural_area                               0\n",
       "did_police_officer_attend_scene_of_accident       0\n",
       "lsoa_of_accident_location                      5544\n",
       "district                                          0\n",
       "converted_date                                    0\n",
       "converted_time                                   59\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of values that are NaN\n",
    "accidents.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc675d",
   "metadata": {},
   "source": [
    "### Cleaning the time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e0a483e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>converted_date</th>\n",
       "      <th>converted_time</th>\n",
       "      <th>light_conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>2019-05-24</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>2019-05-26</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3644</th>\n",
       "      <td>2019-07-09</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>2019-12-08</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4415</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5730</th>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7673</th>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>2019-10-26</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8938</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9950</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10271</th>\n",
       "      <td>2019-02-27</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11464</th>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11468</th>\n",
       "      <td>2019-09-18</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11701</th>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11836</th>\n",
       "      <td>2019-02-10</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12286</th>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13713</th>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14325</th>\n",
       "      <td>2019-03-29</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15559</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16633</th>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17448</th>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18046</th>\n",
       "      <td>2019-11-27</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18196</th>\n",
       "      <td>2019-02-20</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18507</th>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18789</th>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18826</th>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19200</th>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20192</th>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24777</th>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34226</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34448</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34594</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34608</th>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34679</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34825</th>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35014</th>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35047</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35262</th>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35469</th>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35472</th>\n",
       "      <td>2019-11-14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35679</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35828</th>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36474</th>\n",
       "      <td>2019-12-18</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36538</th>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36831</th>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36851</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36899</th>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37060</th>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37231</th>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37258</th>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37284</th>\n",
       "      <td>2019-07-06</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68053</th>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      converted_date converted_time  light_conditions\n",
       "756       2019-08-30            NaT                 4\n",
       "2409      2019-05-24            NaT                 7\n",
       "2410      2019-05-27            NaT                 1\n",
       "3061      2019-02-17            NaT                 4\n",
       "3301      2019-05-26            NaT                 7\n",
       "3326      2019-05-27            NaT                 1\n",
       "3644      2019-07-09            NaT                 1\n",
       "3816      2019-12-08            NaT                 7\n",
       "4415      2019-08-10            NaT                 4\n",
       "4628      2019-11-01            NaT                 1\n",
       "4787      2019-12-25            NaT                 4\n",
       "5730      2019-09-15            NaT                 4\n",
       "6616      2019-01-10            NaT                 1\n",
       "7673      2019-12-14            NaT                 4\n",
       "7697      2019-10-26            NaT                 1\n",
       "8938      2019-09-21            NaT                 4\n",
       "9950      2019-09-29            NaT                 7\n",
       "10271     2019-02-27            NaT                 1\n",
       "11464     2019-09-16            NaT                 1\n",
       "11468     2019-09-18            NaT                 4\n",
       "11701     2019-12-14            NaT                 4\n",
       "11836     2019-02-10            NaT                 4\n",
       "12286     2019-07-26            NaT                 4\n",
       "13713     2019-06-13            NaT                 4\n",
       "14325     2019-03-29            NaT                 4\n",
       "15559     2019-01-13            NaT                 7\n",
       "16633     2019-03-22            NaT                 1\n",
       "17448     2019-07-12            NaT                 4\n",
       "18046     2019-11-27            NaT                 4\n",
       "18196     2019-02-20            NaT                 1\n",
       "18507     2019-06-20            NaT                 1\n",
       "18789     2019-10-17            NaT                 4\n",
       "18826     2019-11-03            NaT                 7\n",
       "19200     2019-05-15            NaT                 4\n",
       "20192     2019-07-17            NaT                 4\n",
       "24777     2019-09-08            NaT                 4\n",
       "34226     2019-01-07            NaT                 1\n",
       "34448     2019-03-01            NaT                 1\n",
       "34594     2019-04-05            NaT                 1\n",
       "34608     2019-02-15            NaT                 1\n",
       "34679     2019-04-26            NaT                 1\n",
       "34825     2019-06-11            NaT                 1\n",
       "35014     2019-07-29            NaT                 4\n",
       "35047     2019-08-09            NaT                 1\n",
       "35262     2019-09-27            NaT                 4\n",
       "35469     2019-11-07            NaT                 1\n",
       "35472     2019-11-14            NaT                 4\n",
       "35679     2019-01-11            NaT                 1\n",
       "35828     2019-03-15            NaT                 4\n",
       "36474     2019-12-18            NaT                 4\n",
       "36538     2019-02-19            NaT                 4\n",
       "36831     2019-09-20            NaT                 1\n",
       "36851     2019-10-03            NaT                 1\n",
       "36899     2019-11-07            NaT                 4\n",
       "37060     2019-02-11            NaT                 7\n",
       "37231     2019-06-04            NaT                 1\n",
       "37258     2019-06-19            NaT                 1\n",
       "37284     2019-07-06            NaT                 1\n",
       "68053     2019-02-19            NaT                 4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows with time column == NaT\n",
    "accidents[accidents['converted_time'].isnull()][['converted_date',\n",
    "                                                 'converted_time',\n",
    "                                                'light_conditions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7affcb9c",
   "metadata": {},
   "source": [
    "### Checking for correlation between time and light_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d817e144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daylight</th>\n",
       "      <th>lights_lit</th>\n",
       "      <th>lights_unlit</th>\n",
       "      <th>no_lighting</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>76.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>54.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>62.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>52.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00</th>\n",
       "      <td>109.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 05:00:00</th>\n",
       "      <td>257.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 06:00:00</th>\n",
       "      <td>804.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 07:00:00</th>\n",
       "      <td>2743.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 08:00:00</th>\n",
       "      <td>4883.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 09:00:00</th>\n",
       "      <td>3271.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 10:00:00</th>\n",
       "      <td>3040.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 11:00:00</th>\n",
       "      <td>3525.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 12:00:00</th>\n",
       "      <td>3944.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 13:00:00</th>\n",
       "      <td>4265.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 14:00:00</th>\n",
       "      <td>4325.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 15:00:00</th>\n",
       "      <td>5571.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 16:00:00</th>\n",
       "      <td>4600.0</td>\n",
       "      <td>969.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 17:00:00</th>\n",
       "      <td>4140.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 18:00:00</th>\n",
       "      <td>2909.0</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 19:00:00</th>\n",
       "      <td>1781.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 20:00:00</th>\n",
       "      <td>837.0</td>\n",
       "      <td>1743.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 21:00:00</th>\n",
       "      <td>256.0</td>\n",
       "      <td>1779.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 22:00:00</th>\n",
       "      <td>82.0</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:00:00</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     daylight  lights_lit  lights_unlit  no_lighting  unknown\n",
       "time                                                                         \n",
       "2018-01-01 00:00:00      76.0       897.0          19.0        145.0     74.0\n",
       "2018-01-01 01:00:00      54.0       611.0          21.0        110.0     54.0\n",
       "2018-01-01 02:00:00      62.0       449.0           6.0         87.0     37.0\n",
       "2018-01-01 03:00:00      52.0       377.0           8.0         58.0     39.0\n",
       "2018-01-01 04:00:00     109.0       311.0          10.0         49.0     35.0\n",
       "2018-01-01 05:00:00     257.0       315.0           9.0         78.0     45.0\n",
       "2018-01-01 06:00:00     804.0       417.0          19.0         85.0     57.0\n",
       "2018-01-01 07:00:00    2743.0       328.0          16.0         72.0     76.0\n",
       "2018-01-01 08:00:00    4883.0        40.0          11.0         19.0     13.0\n",
       "2018-01-01 09:00:00    3271.0        24.0           8.0          4.0      4.0\n",
       "2018-01-01 10:00:00    3040.0        24.0           7.0          5.0      3.0\n",
       "2018-01-01 11:00:00    3525.0        36.0           6.0          3.0      9.0\n",
       "2018-01-01 12:00:00    3944.0        34.0           5.0          3.0      4.0\n",
       "2018-01-01 13:00:00    4265.0        31.0          10.0          6.0     13.0\n",
       "2018-01-01 14:00:00    4325.0        39.0          11.0          4.0      8.0\n",
       "2018-01-01 15:00:00    5571.0       145.0          23.0         18.0     15.0\n",
       "2018-01-01 16:00:00    4600.0       969.0          43.0        138.0     86.0\n",
       "2018-01-01 17:00:00    4140.0      1755.0          52.0        232.0    178.0\n",
       "2018-01-01 18:00:00    2909.0      1943.0          42.0        235.0    208.0\n",
       "2018-01-01 19:00:00    1781.0      1860.0          42.0        193.0    191.0\n",
       "2018-01-01 20:00:00     837.0      1743.0          31.0        227.0    165.0\n",
       "2018-01-01 21:00:00     256.0      1779.0          28.0        233.0    158.0\n",
       "2018-01-01 22:00:00      82.0      1686.0          21.0        210.0    144.0\n",
       "2018-01-01 23:00:00      57.0      1228.0          19.0        169.0    110.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light = accidents.loc[accidents.converted_time.notnull(), ['converted_time', 'light_conditions']]\n",
    "\n",
    "# adding dummy date to converted-time column for manipulation\n",
    "date = str(datetime.datetime.strptime('2018-01-01', '%Y-%m-%d').date())\n",
    "light['converted_time'] = pd.to_datetime(date + \" \" + light.converted_time.astype(str))\n",
    "\n",
    "# do one-hot encoding for the light_conditions column\n",
    "light = pd.concat([light, pd.get_dummies(light.light_conditions)], axis=1).drop(['light_conditions', -1], axis=1)\n",
    "#srss['average_time'] = srss.apply(lambda row: find_avg_time(row.sunrise, row.sunset), axis=1)\n",
    "light.columns = ['time', 'daylight', 'lights_lit',\n",
    "                 'lights_unlit', 'no_lighting', 'unknown']\n",
    "\n",
    "# group the dataframe by hour of day\n",
    "light.groupby(pd.Grouper(key='time', freq='H')).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6ac74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in sunrise_sunset.csv as dataframe\n",
    "srss = pd.read_csv(additional_directory / 'sunrise_sunset.csv')\n",
    "\n",
    "# string formatting\n",
    "srss['sunrise'] = srss['sunrise'] + ':00'\n",
    "srss['sunset'] = srss['sunset'] + ':00'\n",
    "srss['day_length'] = srss['day_length'] + ':00'\n",
    "# create converted_date feature as np.datetime64 dtype\n",
    "srss['converted_date'] = pd.to_datetime(srss['date'])\n",
    "# drop original date column\n",
    "srss = srss.drop(['date'], axis=1)\n",
    "# convert sunrise and sunset to np.timedelta64 dtype\n",
    "srss['sunrise'] = pd.to_timedelta(srss['sunrise'])\n",
    "srss['sunset'] = pd.to_timedelta(srss['sunset'])\n",
    "\n",
    "\n",
    "def find_avg_time(first_time, second_time):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Given two times, find the average time between them\n",
    "        (t1 + t2) / 2\n",
    "    \"\"\"\n",
    "    time1_s = first_time.total_seconds()\n",
    "    time2_s = second_time.total_seconds()\n",
    "    time = (time1_s + time2_s) / 2 - 3600\n",
    "    return datetime.datetime.fromtimestamp(time).strftime(\"%H:%M\")\n",
    "    \n",
    "# create average time column using the find_avg_time function\n",
    "srss['average_time'] = srss.apply(lambda row: find_avg_time(row.sunrise, row.sunset), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ca8fe15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>day_length</th>\n",
       "      <th>converted_date</th>\n",
       "      <th>average_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 16:01:00</td>\n",
       "      <td>07:54:00</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>12:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 16:02:00</td>\n",
       "      <td>07:55:00</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>12:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 16:03:00</td>\n",
       "      <td>07:56:00</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>12:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 16:04:00</td>\n",
       "      <td>07:58:00</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>12:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 16:05:00</td>\n",
       "      <td>07:59:00</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>12:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 15:56:00</td>\n",
       "      <td>07:49:00</td>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>12:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 15:57:00</td>\n",
       "      <td>07:50:00</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>12:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 15:58:00</td>\n",
       "      <td>07:51:00</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>12:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 15:59:00</td>\n",
       "      <td>07:52:00</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>12:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 15:59:00</td>\n",
       "      <td>07:53:00</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>12:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sunrise          sunset day_length converted_date average_time\n",
       "0   0 days 08:06:00 0 days 16:01:00   07:54:00     2019-01-01        12:03\n",
       "1   0 days 08:06:00 0 days 16:02:00   07:55:00     2019-01-02        12:04\n",
       "2   0 days 08:06:00 0 days 16:03:00   07:56:00     2019-01-03        12:04\n",
       "3   0 days 08:06:00 0 days 16:04:00   07:58:00     2019-01-04        12:05\n",
       "4   0 days 08:06:00 0 days 16:05:00   07:59:00     2019-01-05        12:05\n",
       "..              ...             ...        ...            ...          ...\n",
       "360 0 days 08:06:00 0 days 15:56:00   07:49:00     2019-12-27        12:01\n",
       "361 0 days 08:06:00 0 days 15:57:00   07:50:00     2019-12-28        12:01\n",
       "362 0 days 08:06:00 0 days 15:58:00   07:51:00     2019-12-29        12:02\n",
       "363 0 days 08:06:00 0 days 15:59:00   07:52:00     2019-12-30        12:02\n",
       "364 0 days 08:06:00 0 days 15:59:00   07:53:00     2019-12-31        12:02\n",
       "\n",
       "[365 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2efb8f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accident_index', 'longitude', 'latitude', 'police_force',\n",
       "       'accident_severity', 'number_of_vehicles', 'number_of_casualties',\n",
       "       'date', 'day_of_week', 'time', 'local_authority_(district)',\n",
       "       'local_authority_(highway)', '1st_road_class', '1st_road_number',\n",
       "       'road_type', 'speed_limit', 'junction_detail', 'junction_control',\n",
       "       '2nd_road_class', '2nd_road_number',\n",
       "       'pedestrian_crossing-human_control',\n",
       "       'pedestrian_crossing-physical_facilities', 'light_conditions',\n",
       "       'weather_conditions', 'road_surface_conditions',\n",
       "       'special_conditions_at_site', 'carriageway_hazards',\n",
       "       'urban_or_rural_area', 'did_police_officer_attend_scene_of_accident',\n",
       "       'lsoa_of_accident_location', 'district', 'converted_date',\n",
       "       'converted_time', 'average_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns which are not needed\n",
    "srss = srss.drop(['sunrise', 'sunset', 'day_length'], axis=1)\n",
    "# merge useful columns of srss to accidents dataframe on converted_date column\n",
    "accidents = pd.merge(accidents, srss, on=['converted_date'])\n",
    "\n",
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7985b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accident_index', 'longitude', 'latitude', 'police_force',\n",
       "       'accident_severity', 'number_of_vehicles', 'number_of_casualties',\n",
       "       'date', 'day_of_week', 'time', 'local_authority_(district)',\n",
       "       'local_authority_(highway)', '1st_road_class', '1st_road_number',\n",
       "       'road_type', 'speed_limit', 'junction_detail', 'junction_control',\n",
       "       '2nd_road_class', '2nd_road_number',\n",
       "       'pedestrian_crossing-human_control',\n",
       "       'pedestrian_crossing-physical_facilities', 'light_conditions',\n",
       "       'weather_conditions', 'road_surface_conditions',\n",
       "       'special_conditions_at_site', 'carriageway_hazards',\n",
       "       'urban_or_rural_area', 'did_police_officer_attend_scene_of_accident',\n",
       "       'lsoa_of_accident_location', 'district', 'converted_date',\n",
       "       'converted_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask for values with null values in converted_time column\n",
    "missing_time_mask = accidents[\"converted_time\"].isnull()\n",
    "\n",
    "# impute missing times with average time \n",
    "accidents.loc[missing_time_mask, 'converted_time'] = accidents.loc[missing_time_mask, 'average_time']\n",
    "\n",
    "accidents = accidents.drop(['average_time'], axis=1)\n",
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0bc2c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2019-01-15 21:45:00\n",
       "1       2019-01-15 08:42:00\n",
       "2       2019-01-15 07:08:00\n",
       "3       2019-01-15 21:05:00\n",
       "4       2019-01-15 16:10:00\n",
       "                ...        \n",
       "73315   2019-03-18 16:10:00\n",
       "73316   2019-03-18 10:10:00\n",
       "73317   2019-03-18 12:04:00\n",
       "73318   2019-03-18 01:00:00\n",
       "73319   2019-03-18 16:40:00\n",
       "Name: datetime, Length: 73320, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a single 'datetime' feature in ISO 8601 format\n",
    "# using numpy.datetime64 object\n",
    "\n",
    "accidents['datetime'] = pd.to_datetime(accidents['converted_date'].astype(str) + \" \" + accidents['converted_time'].astype(str),\n",
    "               format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# dropping the original date and time columns\n",
    "accidents = accidents.drop(['date', 'time'], axis=1)\n",
    "accidents['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6381351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accident_index                                    0\n",
       "longitude                                         0\n",
       "latitude                                          0\n",
       "police_force                                      0\n",
       "accident_severity                                 0\n",
       "number_of_vehicles                                0\n",
       "number_of_casualties                              0\n",
       "day_of_week                                       0\n",
       "local_authority_(district)                        0\n",
       "local_authority_(highway)                         0\n",
       "1st_road_class                                    0\n",
       "1st_road_number                                   0\n",
       "road_type                                         0\n",
       "speed_limit                                       0\n",
       "junction_detail                                   0\n",
       "junction_control                                  0\n",
       "2nd_road_class                                    0\n",
       "2nd_road_number                                   0\n",
       "pedestrian_crossing-human_control                 0\n",
       "pedestrian_crossing-physical_facilities           0\n",
       "light_conditions                                  0\n",
       "weather_conditions                                0\n",
       "road_surface_conditions                           0\n",
       "special_conditions_at_site                        0\n",
       "carriageway_hazards                               0\n",
       "urban_or_rural_area                               0\n",
       "did_police_officer_attend_scene_of_accident       0\n",
       "lsoa_of_accident_location                      5544\n",
       "district                                          0\n",
       "converted_date                                    0\n",
       "converted_time                                    0\n",
       "datetime                                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time column is now cleaned\n",
    "accidents.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1de74127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>decimal_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-15 21:45:00</td>\n",
       "      <td>21.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-15 08:42:00</td>\n",
       "      <td>8.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-15 07:08:00</td>\n",
       "      <td>7.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-15 21:05:00</td>\n",
       "      <td>21.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-15 16:10:00</td>\n",
       "      <td>16.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  decimal_time\n",
       "0 2019-01-15 21:45:00     21.750000\n",
       "1 2019-01-15 08:42:00      8.700000\n",
       "2 2019-01-15 07:08:00      7.133333\n",
       "3 2019-01-15 21:05:00     21.083333\n",
       "4 2019-01-15 16:10:00     16.166667"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a decimal time column using the time component of 'converted_time'\n",
    "def convert_to_decimal(df, new_col, original_col='datetime',):\n",
    "    \"\"\"Convert datetime.time value to decimal\"\"\"\n",
    "    df[new_col] = df[original_col].dt.hour + df[original_col].dt.minute / 60\n",
    "    \n",
    "# create decimal_time column\n",
    "convert_to_decimal(accidents, 'decimal_time', 'datetime')\n",
    "\n",
    "accidents.loc[:, ['datetime', 'decimal_time']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61702dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31850</th>\n",
       "      <td>2019-06-30 19:00:00</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49162</th>\n",
       "      <td>2019-09-25 08:04:00</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9837</th>\n",
       "      <td>2019-02-22 16:13:00</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9376</th>\n",
       "      <td>2019-02-21 15:20:00</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47786</th>\n",
       "      <td>2019-09-19 18:00:00</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805</th>\n",
       "      <td>2019-03-05 11:01:00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32702</th>\n",
       "      <td>2019-07-04 16:00:00</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15815</th>\n",
       "      <td>2019-03-29 15:35:00</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25330</th>\n",
       "      <td>2019-05-26 13:30:00</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11924</th>\n",
       "      <td>2019-03-06 21:36:00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime  day_of_year\n",
       "31850 2019-06-30 19:00:00          181\n",
       "49162 2019-09-25 08:04:00          268\n",
       "9837  2019-02-22 16:13:00           53\n",
       "9376  2019-02-21 15:20:00           52\n",
       "47786 2019-09-19 18:00:00          262\n",
       "11805 2019-03-05 11:01:00           64\n",
       "32702 2019-07-04 16:00:00          185\n",
       "15815 2019-03-29 15:35:00           88\n",
       "25330 2019-05-26 13:30:00          146\n",
       "11924 2019-03-06 21:36:00           65"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_day_of_year(datetime_val):\n",
    "    \"\"\"Return the day of the year for a given datetime.date value\"\"\"\n",
    "    return datetime_val.dayofyear\n",
    "\n",
    "accidents['day_of_year'] = accidents['datetime'].apply(to_day_of_year)\n",
    "accidents['day_of_year'] = accidents['day_of_year'].fillna(-10)\n",
    "accidents['day_of_year'] = accidents['day_of_year'].astype('int32')\n",
    "\n",
    "# 10 randomly sampled columns\n",
    "accidents.loc[:, ['datetime', 'day_of_year']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5618edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save serialised dataframe for loading in other notebooks\n",
    "accidents.to_pickle('accidents_cleaned.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
