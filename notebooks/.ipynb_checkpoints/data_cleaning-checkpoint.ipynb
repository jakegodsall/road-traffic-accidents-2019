{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a5d797",
   "metadata": {},
   "source": [
    "# Big Data Project\n",
    "\n",
    "## Contents\n",
    "\n",
    "The code written for this report is partitioned into separate notebooks according to topic.\n",
    "\n",
    "A general guidel, according to the structure of the report, would to be to view in the following order:\n",
    "\n",
    "1. data_cleaning.ipynb + (data_generation.ipynb)\n",
    "2. EDA.ipynb\n",
    "3. clustering.ipynb\n",
    "4. hypothesis_rural_accidents.ipynb\n",
    "5. hypothesis_sunrise_sunset.ipynb\n",
    "6. hypothesis_football.ipynb\n",
    "7. predictive_model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0685404",
   "metadata": {},
   "source": [
    "## Packages\n",
    "Importing all necessary packages to run the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd89783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages for data manipulation\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e4867",
   "metadata": {},
   "source": [
    "## Directory navigation and creation\n",
    "Creating pathlib.Path objects for cross-platform navigation and loading the three datasets into pandas DataFrame objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e1de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file locations:\n",
      "\n",
      "/Volumes/GoogleDrive/My Drive/Dev/TrafficAccidents/data/accidents2019.csv\n",
      "/Volumes/GoogleDrive/My Drive/Dev/TrafficAccidents/data/casualties2019.csv\n",
      "/Volumes/GoogleDrive/My Drive/Dev/TrafficAccidents/data/vehicles2019.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accident_index</th>\n",
       "      <th>location_easting_osgr</th>\n",
       "      <th>location_northing_osgr</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>police_force</th>\n",
       "      <th>accident_severity</th>\n",
       "      <th>number_of_vehicles</th>\n",
       "      <th>number_of_casualties</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>pedestrian_crossing-human_control</th>\n",
       "      <th>pedestrian_crossing-physical_facilities</th>\n",
       "      <th>light_conditions</th>\n",
       "      <th>weather_conditions</th>\n",
       "      <th>road_surface_conditions</th>\n",
       "      <th>special_conditions_at_site</th>\n",
       "      <th>carriageway_hazards</th>\n",
       "      <th>urban_or_rural_area</th>\n",
       "      <th>did_police_officer_attend_scene_of_accident</th>\n",
       "      <th>lsoa_of_accident_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019010128300</td>\n",
       "      <td>528218.0</td>\n",
       "      <td>180407.0</td>\n",
       "      <td>-0.153842</td>\n",
       "      <td>51.508057</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18/02/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>E01004762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019010152270</td>\n",
       "      <td>530219.0</td>\n",
       "      <td>172463.0</td>\n",
       "      <td>-0.127949</td>\n",
       "      <td>51.436208</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>E01003117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019010155191</td>\n",
       "      <td>530222.0</td>\n",
       "      <td>182543.0</td>\n",
       "      <td>-0.124193</td>\n",
       "      <td>51.526795</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E01000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019010155192</td>\n",
       "      <td>525531.0</td>\n",
       "      <td>184605.0</td>\n",
       "      <td>-0.191044</td>\n",
       "      <td>51.546387</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E01000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019010155194</td>\n",
       "      <td>524920.0</td>\n",
       "      <td>184004.0</td>\n",
       "      <td>-0.200064</td>\n",
       "      <td>51.541121</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E01000546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  accident_index  location_easting_osgr  location_northing_osgr  longitude  \\\n",
       "0  2019010128300               528218.0                180407.0  -0.153842   \n",
       "1  2019010152270               530219.0                172463.0  -0.127949   \n",
       "2  2019010155191               530222.0                182543.0  -0.124193   \n",
       "3  2019010155192               525531.0                184605.0  -0.191044   \n",
       "4  2019010155194               524920.0                184004.0  -0.200064   \n",
       "\n",
       "    latitude  police_force  accident_severity  number_of_vehicles  \\\n",
       "0  51.508057             1                  3                   2   \n",
       "1  51.436208             1                  3                   2   \n",
       "2  51.526795             1                  3                   2   \n",
       "3  51.546387             1                  2                   1   \n",
       "4  51.541121             1                  3                   2   \n",
       "\n",
       "   number_of_casualties        date  ...  pedestrian_crossing-human_control  \\\n",
       "0                     3  18/02/2019  ...                                  0   \n",
       "1                     1  15/01/2019  ...                                 -1   \n",
       "2                     1  01/01/2019  ...                                  0   \n",
       "3                     1  01/01/2019  ...                                  0   \n",
       "4                     2  01/01/2019  ...                                  0   \n",
       "\n",
       "  pedestrian_crossing-physical_facilities  light_conditions  \\\n",
       "0                                       5                 1   \n",
       "1                                      -1                 4   \n",
       "2                                       0                 4   \n",
       "3                                       0                 4   \n",
       "4                                       0                 4   \n",
       "\n",
       "  weather_conditions  road_surface_conditions  special_conditions_at_site  \\\n",
       "0                  1                        1                           0   \n",
       "1                  1                        1                           0   \n",
       "2                  1                        1                           0   \n",
       "3                  1                        1                           0   \n",
       "4                  1                        1                           0   \n",
       "\n",
       "   carriageway_hazards  urban_or_rural_area  \\\n",
       "0                    0                    1   \n",
       "1                    0                    1   \n",
       "2                    0                    1   \n",
       "3                    0                    1   \n",
       "4                    0                    1   \n",
       "\n",
       "   did_police_officer_attend_scene_of_accident  lsoa_of_accident_location  \n",
       "0                                            3                  E01004762  \n",
       "1                                            3                  E01003117  \n",
       "2                                            1                  E01000943  \n",
       "3                                            1                  E01000973  \n",
       "4                                            1                  E01000546  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Path object for current working directory\n",
    "cwd = Path('./')\n",
    "root = cwd.resolve().parent\n",
    "# creating Path object for additional data directory\n",
    "additional_data_dir = root / 'additional_data'\n",
    "# create new directory for additional data\n",
    "Path(additional_data_dir).mkdir(exist_ok=True)\n",
    "\n",
    "# creating Path object for plots directroy\n",
    "plots_dir = root / 'plots'\n",
    "# create new directory for plots\n",
    "Path(plots_dir).mkdir(exist_ok=True)\n",
    "\n",
    "# defining the directory to original data\n",
    "data_dir = root / 'data'\n",
    "additional_directory = root / 'additional_data'\n",
    "\n",
    "# list the .csv files for the project\n",
    "print(\"Data file locations:\\n\")\n",
    "for file in data_dir.glob('*.csv'):\n",
    "    print(file)\n",
    "    \n",
    "# reading in .csv files to dataframes\n",
    "vehicles = pd.read_csv(data_dir / 'vehicles2019.csv', dtype={'Accident_Index': str})\n",
    "casualties = pd.read_csv(data_dir / 'casualties2019.csv', dtype={'Accident_Index': str})\n",
    "# cleaned accidents DataFrame\n",
    "accidents = pd.read_csv(data_dir / 'accidents2019.csv', dtype={'Accident_Index': str,\n",
    "                                                               'LSOA_of_Accident_Location': str})\n",
    "\n",
    "# convert column names to lowercase for ease of indexing\n",
    "def lower_columns(df):\n",
    "    \"\"\"\n",
    "    Defintion:\n",
    "        convert column names to lower case\n",
    "    \"\"\"\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    \n",
    "# converting all column names to lower case\n",
    "lower_columns(vehicles)\n",
    "lower_columns(casualties)\n",
    "lower_columns(accidents)\n",
    "\n",
    "accidents.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07326ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accident_index                                    0\n",
       "location_easting_osgr                            28\n",
       "location_northing_osgr                           28\n",
       "longitude                                        28\n",
       "latitude                                         28\n",
       "police_force                                      0\n",
       "accident_severity                                 0\n",
       "number_of_vehicles                                0\n",
       "number_of_casualties                              0\n",
       "date                                              0\n",
       "day_of_week                                       0\n",
       "time                                             63\n",
       "local_authority_(district)                        0\n",
       "local_authority_(highway)                         0\n",
       "1st_road_class                                    0\n",
       "1st_road_number                                   0\n",
       "road_type                                         0\n",
       "speed_limit                                       0\n",
       "junction_detail                                   0\n",
       "junction_control                                  0\n",
       "2nd_road_class                                    0\n",
       "2nd_road_number                                   0\n",
       "pedestrian_crossing-human_control                 0\n",
       "pedestrian_crossing-physical_facilities           0\n",
       "light_conditions                                  0\n",
       "weather_conditions                                0\n",
       "road_surface_conditions                           0\n",
       "special_conditions_at_site                        0\n",
       "carriageway_hazards                               0\n",
       "urban_or_rural_area                               0\n",
       "did_police_officer_attend_scene_of_accident       0\n",
       "lsoa_of_accident_location                      5714\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking features with NaN values\n",
    "accidents.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970e97aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117536, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab621bb",
   "metadata": {},
   "source": [
    "## Data Cleaning and Feature Creation\n",
    "\n",
    "The two main areas of data cleaning is for the geospatial coordinates (28 NaN) and time (63 NAN)\n",
    "\n",
    "1. Latitude and longitude imputation\n",
    "    \n",
    "    **source**: https://simplemaps.com/data/gb-cities\n",
    "    \n",
    "    \n",
    "    \n",
    "2. Datetime formatting and time imputation\n",
    "\n",
    "    **source**: https://www.sunrise-and-sunset.com/en/sun/united-kingdom/london/2019/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a135bc1",
   "metadata": {},
   "source": [
    "### Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d9a938d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the local_authority.csv file of local_athority data that came with the original accident data\n",
    "local_authorities = pd.read_csv(additional_directory / 'local_authority.csv')\n",
    "local_authorities.columns = ['local_authority_(district)', 'district']\n",
    "\n",
    "# merge the accidents dataframe with the local_authorities dataframe on 'local_authority_(district)'\n",
    "accidents = pd.merge(accidents, local_authorities, on=['local_authority_(district)'])\n",
    "\n",
    "accidents[['longitude', 'latitude', 'local_authority_(district)', 'district']]\n",
    "accidents.district = accidents.district.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e91aaa99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude_new</th>\n",
       "      <th>longitude_new</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.5072</td>\n",
       "      <td>-0.1275</td>\n",
       "      <td>london, city of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.4800</td>\n",
       "      <td>-1.9025</td>\n",
       "      <td>birmingham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.4794</td>\n",
       "      <td>-2.2453</td>\n",
       "      <td>manchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.7997</td>\n",
       "      <td>-1.5492</td>\n",
       "      <td>leeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.0077</td>\n",
       "      <td>-1.6578</td>\n",
       "      <td>newcastle upon tyne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>53.4960</td>\n",
       "      <td>-1.4120</td>\n",
       "      <td>rotherham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>57.2670</td>\n",
       "      <td>-2.1920</td>\n",
       "      <td>aberdeenshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>51.6116</td>\n",
       "      <td>-3.5842</td>\n",
       "      <td>bridgend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>51.1536</td>\n",
       "      <td>1.3714</td>\n",
       "      <td>kent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>52.0500</td>\n",
       "      <td>-0.6940</td>\n",
       "      <td>milton keynes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2680 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude_new  longitude_new             district\n",
       "0          51.5072        -0.1275      london, city of\n",
       "1          52.4800        -1.9025           birmingham\n",
       "2          53.4794        -2.2453           manchester\n",
       "3          53.7997        -1.5492                leeds\n",
       "4          55.0077        -1.6578  newcastle upon tyne\n",
       "...            ...            ...                  ...\n",
       "2675       53.4960        -1.4120            rotherham\n",
       "2676       57.2670        -2.1920        aberdeenshire\n",
       "2677       51.6116        -3.5842             bridgend\n",
       "2678       51.1536         1.3714                 kent\n",
       "2679       52.0500        -0.6940        milton keynes\n",
       "\n",
       "[2680 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the latitude, longitude and admin_name columns of the city_coords.csv file\n",
    "cities = pd.read_csv(additional_directory / 'city_coords.csv', usecols=['lat', 'lng', 'admin_name'])\n",
    "cities.columns = ['latitude_new', 'longitude_new', 'district']\n",
    "cities.district = cities.district.str.lower()\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be2efe9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Districts with missing coordinate data: {'west dorset', 'adur', 'wigan', 'selby', 'cheshire west and chester', 'north east lincolnshire', 'medway', 'powys', 'flintshire', 'rugby', 'liverpool', 'warrington', 'wirral', 'scarborough', 'harrogate', 'hambleton', 'cheshire east', 'ryedale', 'wakefield', 'cardiff'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hambleton                    4\n",
       "harrogate                    3\n",
       "selby                        3\n",
       "ryedale                      2\n",
       "north east lincolnshire      1\n",
       "cardiff                      1\n",
       "flintshire                   1\n",
       "west dorset                  1\n",
       "adur                         1\n",
       "medway                       1\n",
       "rugby                        1\n",
       "wigan                        1\n",
       "wakefield                    1\n",
       "wirral                       1\n",
       "scarborough                  1\n",
       "warrington                   1\n",
       "cheshire west and chester    1\n",
       "cheshire east                1\n",
       "liverpool                    1\n",
       "powys                        1\n",
       "Name: district, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the 'district' of instances with missing coordinate data\n",
    "missing_districts = accidents[accidents.longitude.isnull()]['district']\n",
    "print(f\"Districts with missing coordinate data: {set(missing_districts)}\")\n",
    "len(missing_districts)\n",
    "missing_districts.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c6dee37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adur',\n",
       " 'hambleton',\n",
       " 'harrogate',\n",
       " 'rugby',\n",
       " 'ryedale',\n",
       " 'scarborough',\n",
       " 'selby',\n",
       " 'west dorset'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the 'districts' with missing coordinate data in our data set that are not in the city_coords.csv file\n",
    "set(missing_districts) - set(cities.district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f538cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2688, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually add these districts to the cities df of the city_coords.csv file\n",
    "manual_additions = pd.DataFrame(np.array([50.8348, 0.3101, 'adur', \n",
    "                                          54.2959, 1.3135, 'hambleton',\n",
    "                                          53.9921, 1.5418, 'harrogate',\n",
    "                                          52.3709, 1.2650, 'rugby',\n",
    "                                          54.1698, 0.7282, 'ryedale', \n",
    "                                          54.2831, 0.3998, 'scarborough',\n",
    "                                          53.7835, 1.0672, 'selby', \n",
    "                                          50.7755, 2.5817, 'west dorset']).reshape(-1, 3))\n",
    "manual_additions.columns = ['latitude_new', 'longitude_new', 'district']\n",
    "cities = pd.concat([cities, manual_additions], axis=0)\n",
    "\n",
    "cities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8dd73fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117536, 33)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e67b73a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the 'districts' with missing coordinate data in our data set that are not in the city_coords.csv file\n",
    "set(missing_districts) - set(cities.district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ac4096e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117536, 33)\n",
      "(117536, 35)\n"
     ]
    }
   ],
   "source": [
    "# determine the average coordinates for locations in this district in the cities df\n",
    "cities = cities.groupby('district').median()\n",
    "print(accidents.shape)\n",
    "# inner-join the accidents dataframe with the cities dataframe on the 'district' column\n",
    "accidents = accidents.merge(cities, on='district', how='left')\n",
    "print(accidents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b1be875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accident_index</th>\n",
       "      <th>location_easting_osgr</th>\n",
       "      <th>location_northing_osgr</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>police_force</th>\n",
       "      <th>accident_severity</th>\n",
       "      <th>number_of_vehicles</th>\n",
       "      <th>number_of_casualties</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_conditions</th>\n",
       "      <th>road_surface_conditions</th>\n",
       "      <th>special_conditions_at_site</th>\n",
       "      <th>carriageway_hazards</th>\n",
       "      <th>urban_or_rural_area</th>\n",
       "      <th>did_police_officer_attend_scene_of_accident</th>\n",
       "      <th>lsoa_of_accident_location</th>\n",
       "      <th>district</th>\n",
       "      <th>latitude_new</th>\n",
       "      <th>longitude_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019010128300</td>\n",
       "      <td>528218.0</td>\n",
       "      <td>180407.0</td>\n",
       "      <td>-0.153842</td>\n",
       "      <td>51.508057</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18/02/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>E01004762</td>\n",
       "      <td>westminster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019010155414</td>\n",
       "      <td>527376.0</td>\n",
       "      <td>181377.0</td>\n",
       "      <td>-0.165618</td>\n",
       "      <td>51.516964</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>02/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>E01004658</td>\n",
       "      <td>westminster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019010155567</td>\n",
       "      <td>529979.0</td>\n",
       "      <td>180310.0</td>\n",
       "      <td>-0.128517</td>\n",
       "      <td>51.506783</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>03/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E01004736</td>\n",
       "      <td>westminster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019010155601</td>\n",
       "      <td>527414.0</td>\n",
       "      <td>182102.0</td>\n",
       "      <td>-0.164808</td>\n",
       "      <td>51.523471</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>03/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E01004659</td>\n",
       "      <td>westminster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019010155634</td>\n",
       "      <td>527616.0</td>\n",
       "      <td>181879.0</td>\n",
       "      <td>-0.161979</td>\n",
       "      <td>51.521422</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>03/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E01004661</td>\n",
       "      <td>westminster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117531</th>\n",
       "      <td>2019984106919</td>\n",
       "      <td>312635.0</td>\n",
       "      <td>573392.0</td>\n",
       "      <td>-3.368899</td>\n",
       "      <td>55.047323</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18/05/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dumfries and galloway</td>\n",
       "      <td>54.983</td>\n",
       "      <td>-3.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117532</th>\n",
       "      <td>2019984107019</td>\n",
       "      <td>337522.0</td>\n",
       "      <td>591682.0</td>\n",
       "      <td>-2.983499</td>\n",
       "      <td>55.215407</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>30/05/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dumfries and galloway</td>\n",
       "      <td>54.983</td>\n",
       "      <td>-3.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117533</th>\n",
       "      <td>2019984107219</td>\n",
       "      <td>318544.0</td>\n",
       "      <td>567087.0</td>\n",
       "      <td>-3.274645</td>\n",
       "      <td>54.991685</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21/06/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dumfries and galloway</td>\n",
       "      <td>54.983</td>\n",
       "      <td>-3.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117534</th>\n",
       "      <td>2019984107419</td>\n",
       "      <td>336525.0</td>\n",
       "      <td>584226.0</td>\n",
       "      <td>-2.997491</td>\n",
       "      <td>55.148292</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29/06/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dumfries and galloway</td>\n",
       "      <td>54.983</td>\n",
       "      <td>-3.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117535</th>\n",
       "      <td>201998QC01004</td>\n",
       "      <td>291367.0</td>\n",
       "      <td>608364.0</td>\n",
       "      <td>-3.715064</td>\n",
       "      <td>55.357237</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21/04/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dumfries and galloway</td>\n",
       "      <td>54.983</td>\n",
       "      <td>-3.603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117536 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accident_index  location_easting_osgr  location_northing_osgr  \\\n",
       "0       2019010128300               528218.0                180407.0   \n",
       "1       2019010155414               527376.0                181377.0   \n",
       "2       2019010155567               529979.0                180310.0   \n",
       "3       2019010155601               527414.0                182102.0   \n",
       "4       2019010155634               527616.0                181879.0   \n",
       "...               ...                    ...                     ...   \n",
       "117531  2019984106919               312635.0                573392.0   \n",
       "117532  2019984107019               337522.0                591682.0   \n",
       "117533  2019984107219               318544.0                567087.0   \n",
       "117534  2019984107419               336525.0                584226.0   \n",
       "117535  201998QC01004               291367.0                608364.0   \n",
       "\n",
       "        longitude   latitude  police_force  accident_severity  \\\n",
       "0       -0.153842  51.508057             1                  3   \n",
       "1       -0.165618  51.516964             1                  3   \n",
       "2       -0.128517  51.506783             1                  2   \n",
       "3       -0.164808  51.523471             1                  2   \n",
       "4       -0.161979  51.521422             1                  3   \n",
       "...           ...        ...           ...                ...   \n",
       "117531  -3.368899  55.047323            98                  3   \n",
       "117532  -2.983499  55.215407            98                  3   \n",
       "117533  -3.274645  54.991685            98                  3   \n",
       "117534  -2.997491  55.148292            98                  3   \n",
       "117535  -3.715064  55.357237            98                  2   \n",
       "\n",
       "        number_of_vehicles  number_of_casualties        date  ...  \\\n",
       "0                        2                     3  18/02/2019  ...   \n",
       "1                        3                     1  02/01/2019  ...   \n",
       "2                        1                     1  03/01/2019  ...   \n",
       "3                        3                     2  03/01/2019  ...   \n",
       "4                        2                     1  03/01/2019  ...   \n",
       "...                    ...                   ...         ...  ...   \n",
       "117531                   1                     1  18/05/2019  ...   \n",
       "117532                   4                     1  30/05/2019  ...   \n",
       "117533                   2                     1  21/06/2019  ...   \n",
       "117534                   1                     1  29/06/2019  ...   \n",
       "117535                   1                     1  21/04/2019  ...   \n",
       "\n",
       "        weather_conditions road_surface_conditions  \\\n",
       "0                        1                       1   \n",
       "1                        1                       1   \n",
       "2                        1                       1   \n",
       "3                        1                       1   \n",
       "4                        1                       1   \n",
       "...                    ...                     ...   \n",
       "117531                   1                       2   \n",
       "117532                   1                       2   \n",
       "117533                   1                       1   \n",
       "117534                   1                       1   \n",
       "117535                   1                       1   \n",
       "\n",
       "        special_conditions_at_site carriageway_hazards  urban_or_rural_area  \\\n",
       "0                                0                   0                    1   \n",
       "1                                0                   0                    1   \n",
       "2                                0                   0                    1   \n",
       "3                                0                   0                    1   \n",
       "4                                0                   0                    1   \n",
       "...                            ...                 ...                  ...   \n",
       "117531                           0                   0                    2   \n",
       "117532                           0                   0                    2   \n",
       "117533                           0                   0                    2   \n",
       "117534                           0                   0                    2   \n",
       "117535                           0                   0                    2   \n",
       "\n",
       "        did_police_officer_attend_scene_of_accident  \\\n",
       "0                                                 3   \n",
       "1                                                 3   \n",
       "2                                                 1   \n",
       "3                                                 1   \n",
       "4                                                 1   \n",
       "...                                             ...   \n",
       "117531                                            1   \n",
       "117532                                            1   \n",
       "117533                                            2   \n",
       "117534                                            2   \n",
       "117535                                            1   \n",
       "\n",
       "        lsoa_of_accident_location               district  latitude_new  \\\n",
       "0                       E01004762            westminster           NaN   \n",
       "1                       E01004658            westminster           NaN   \n",
       "2                       E01004736            westminster           NaN   \n",
       "3                       E01004659            westminster           NaN   \n",
       "4                       E01004661            westminster           NaN   \n",
       "...                           ...                    ...           ...   \n",
       "117531                        NaN  dumfries and galloway        54.983   \n",
       "117532                        NaN  dumfries and galloway        54.983   \n",
       "117533                        NaN  dumfries and galloway        54.983   \n",
       "117534                        NaN  dumfries and galloway        54.983   \n",
       "117535                        NaN  dumfries and galloway        54.983   \n",
       "\n",
       "        longitude_new  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "117531         -3.603  \n",
       "117532         -3.603  \n",
       "117533         -3.603  \n",
       "117534         -3.603  \n",
       "117535         -3.603  \n",
       "\n",
       "[117536 rows x 35 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cc9c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the missing longitude and latitude values with the new longitude and latitude values from the cities dataframe\n",
    "accidents.loc[accidents.longitude.isnull(), 'longitude'] = accidents.loc[accidents.longitude.isnull(), 'longitude_new']\n",
    "accidents.loc[accidents.latitude.isnull(), 'latitude'] = accidents.loc[accidents.latitude.isnull(), 'latitude_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f909b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accident_index                                    0\n",
       "longitude                                         0\n",
       "latitude                                          0\n",
       "police_force                                      0\n",
       "accident_severity                                 0\n",
       "number_of_vehicles                                0\n",
       "number_of_casualties                              0\n",
       "date                                              0\n",
       "day_of_week                                       0\n",
       "time                                             63\n",
       "local_authority_(district)                        0\n",
       "local_authority_(highway)                         0\n",
       "1st_road_class                                    0\n",
       "1st_road_number                                   0\n",
       "road_type                                         0\n",
       "speed_limit                                       0\n",
       "junction_detail                                   0\n",
       "junction_control                                  0\n",
       "2nd_road_class                                    0\n",
       "2nd_road_number                                   0\n",
       "pedestrian_crossing-human_control                 0\n",
       "pedestrian_crossing-physical_facilities           0\n",
       "light_conditions                                  0\n",
       "weather_conditions                                0\n",
       "road_surface_conditions                           0\n",
       "special_conditions_at_site                        0\n",
       "carriageway_hazards                               0\n",
       "urban_or_rural_area                               0\n",
       "did_police_officer_attend_scene_of_accident       0\n",
       "lsoa_of_accident_location                      5714\n",
       "district                                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the columns used for this imputation, as well as the osgr coordinates (replicated information)\n",
    "accidents = accidents.drop(['location_easting_osgr', 'location_northing_osgr',\n",
    "                            'latitude_new', 'longitude_new'], axis=1)\n",
    "accidents.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e89205ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117536, 31)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed06b4",
   "metadata": {},
   "source": [
    "The `NaN` latitude and longitude values have been imputed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319dc11",
   "metadata": {},
   "source": [
    "### Datetime formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fadae9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted_date dtype: datetime64[ns]\n",
      "converted_time dtype: object\n",
      "<class 'datetime.time'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>converted_date</th>\n",
       "      <th>converted_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-18</td>\n",
       "      <td>17:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>07:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>10:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>17:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>19:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117531</th>\n",
       "      <td>2019-05-18</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117532</th>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>08:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117533</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>15:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117534</th>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>14:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117535</th>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>12:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117536 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       converted_date converted_time\n",
       "0          2019-02-18       17:50:00\n",
       "1          2019-01-02       07:45:00\n",
       "2          2019-01-03       10:45:00\n",
       "3          2019-01-03       17:20:00\n",
       "4          2019-01-03       19:10:00\n",
       "...               ...            ...\n",
       "117531     2019-05-18       01:00:00\n",
       "117532     2019-05-30       08:46:00\n",
       "117533     2019-06-21       15:30:00\n",
       "117534     2019-06-29       14:10:00\n",
       "117535     2019-04-21       12:45:00\n",
       "\n",
       "[117536 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 'converted_date' and 'converted_column' features for manipulation of dates and times\n",
    "accidents['converted_date'] = pd.to_datetime(accidents['date'],\n",
    "                                              format='%d/%m/%Y')\n",
    "accidents['converted_time'] = pd.to_datetime(accidents['time'],\n",
    "                                             errors='coerce',\n",
    "                                             format='%H:%M').dt.time\n",
    "\n",
    "print(f'converted_date dtype: {accidents[\"converted_date\"].dtype}')\n",
    "print(f'converted_time dtype: {accidents[\"converted_time\"].dtype}')\n",
    "print(type(accidents['converted_time'][0]))\n",
    "\n",
    "accidents[['converted_date', 'converted_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11171f2f",
   "metadata": {},
   "source": [
    "So the converted_date column has a dtype of datetime64[ns]\n",
    "and the converted_time column has a dtype of object consisting of datetime.time elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f60de90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accident_index                                    0\n",
       "longitude                                         0\n",
       "latitude                                          0\n",
       "police_force                                      0\n",
       "accident_severity                                 0\n",
       "number_of_vehicles                                0\n",
       "number_of_casualties                              0\n",
       "date                                              0\n",
       "day_of_week                                       0\n",
       "time                                             63\n",
       "local_authority_(district)                        0\n",
       "local_authority_(highway)                         0\n",
       "1st_road_class                                    0\n",
       "1st_road_number                                   0\n",
       "road_type                                         0\n",
       "speed_limit                                       0\n",
       "junction_detail                                   0\n",
       "junction_control                                  0\n",
       "2nd_road_class                                    0\n",
       "2nd_road_number                                   0\n",
       "pedestrian_crossing-human_control                 0\n",
       "pedestrian_crossing-physical_facilities           0\n",
       "light_conditions                                  0\n",
       "weather_conditions                                0\n",
       "road_surface_conditions                           0\n",
       "special_conditions_at_site                        0\n",
       "carriageway_hazards                               0\n",
       "urban_or_rural_area                               0\n",
       "did_police_officer_attend_scene_of_accident       0\n",
       "lsoa_of_accident_location                      5714\n",
       "district                                          0\n",
       "converted_date                                    0\n",
       "converted_time                                   63\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of values that are NaN\n",
    "accidents.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e9babcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117536, 33)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc675d",
   "metadata": {},
   "source": [
    "### Cleaning the time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e0a483e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>converted_date</th>\n",
       "      <th>converted_time</th>\n",
       "      <th>light_conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2019-02-10</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43902</th>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44073</th>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44100</th>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44126</th>\n",
       "      <td>2019-07-06</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112099</th>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       converted_date converted_time  light_conditions\n",
       "136        2019-02-10            NaT                 4\n",
       "152        2019-02-14            NaT                 4\n",
       "1009       2019-09-02            NaT                 4\n",
       "1232       2019-10-25            NaT                 4\n",
       "2277       2019-08-30            NaT                 4\n",
       "...               ...            ...               ...\n",
       "43902      2019-02-11            NaT                 7\n",
       "44073      2019-06-04            NaT                 1\n",
       "44100      2019-06-19            NaT                 1\n",
       "44126      2019-07-06            NaT                 1\n",
       "112099     2019-02-19            NaT                 4\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows with time column == NaT\n",
    "accidents[accidents['converted_time'].isnull()][['converted_date',\n",
    "                                                 'converted_time',\n",
    "                                                'light_conditions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7affcb9c",
   "metadata": {},
   "source": [
    "### Checking for correlation between time and light_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d817e144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daylight</th>\n",
       "      <th>lights_lit</th>\n",
       "      <th>lights_unlit</th>\n",
       "      <th>no_lighting</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>86.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>76.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>78.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>71.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 05:00:00</th>\n",
       "      <td>401.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 06:00:00</th>\n",
       "      <td>1374.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 07:00:00</th>\n",
       "      <td>4558.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 08:00:00</th>\n",
       "      <td>7996.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 09:00:00</th>\n",
       "      <td>5426.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 10:00:00</th>\n",
       "      <td>5123.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 11:00:00</th>\n",
       "      <td>5873.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 12:00:00</th>\n",
       "      <td>6522.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 13:00:00</th>\n",
       "      <td>6860.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 14:00:00</th>\n",
       "      <td>6905.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 15:00:00</th>\n",
       "      <td>8807.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 16:00:00</th>\n",
       "      <td>7502.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 17:00:00</th>\n",
       "      <td>6626.0</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 18:00:00</th>\n",
       "      <td>4559.0</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 19:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>2676.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 20:00:00</th>\n",
       "      <td>1239.0</td>\n",
       "      <td>2474.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 21:00:00</th>\n",
       "      <td>376.0</td>\n",
       "      <td>2488.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 22:00:00</th>\n",
       "      <td>111.0</td>\n",
       "      <td>2403.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:00:00</th>\n",
       "      <td>71.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     daylight  lights_lit  lights_unlit  no_lighting  unknown\n",
       "time                                                                         \n",
       "2018-01-01 00:00:00      86.0      1250.0          39.0        351.0    104.0\n",
       "2018-01-01 01:00:00      76.0       865.0          42.0        265.0     79.0\n",
       "2018-01-01 02:00:00      78.0       613.0          18.0        204.0     53.0\n",
       "2018-01-01 03:00:00      71.0       536.0          16.0        152.0     52.0\n",
       "2018-01-01 04:00:00     148.0       433.0          20.0        135.0     55.0\n",
       "2018-01-01 05:00:00     401.0       454.0          21.0        216.0     77.0\n",
       "2018-01-01 06:00:00    1374.0       630.0          37.0        251.0    112.0\n",
       "2018-01-01 07:00:00    4558.0       457.0          34.0        166.0    138.0\n",
       "2018-01-01 08:00:00    7996.0        60.0          19.0         34.0     18.0\n",
       "2018-01-01 09:00:00    5426.0        36.0          15.0         10.0     10.0\n",
       "2018-01-01 10:00:00    5123.0        41.0          12.0          9.0      5.0\n",
       "2018-01-01 11:00:00    5873.0        38.0          12.0         21.0     16.0\n",
       "2018-01-01 12:00:00    6522.0        46.0          11.0          7.0     15.0\n",
       "2018-01-01 13:00:00    6860.0        44.0          15.0          9.0     18.0\n",
       "2018-01-01 14:00:00    6905.0        47.0          17.0         13.0     11.0\n",
       "2018-01-01 15:00:00    8807.0       229.0          38.0         66.0     32.0\n",
       "2018-01-01 16:00:00    7502.0      1440.0          73.0        310.0    137.0\n",
       "2018-01-01 17:00:00    6626.0      2608.0          89.0        596.0    279.0\n",
       "2018-01-01 18:00:00    4559.0      2777.0          91.0        623.0    297.0\n",
       "2018-01-01 19:00:00    2698.0      2676.0          77.0        497.0    286.0\n",
       "2018-01-01 20:00:00    1239.0      2474.0          61.0        530.0    232.0\n",
       "2018-01-01 21:00:00     376.0      2488.0          51.0        565.0    223.0\n",
       "2018-01-01 22:00:00     111.0      2403.0          40.0        597.0    210.0\n",
       "2018-01-01 23:00:00      71.0      1731.0          43.0        465.0    168.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light = accidents.loc[accidents.converted_time.notnull(), ['converted_time', 'light_conditions']]\n",
    "\n",
    "# adding dummy date to converted-time column for manipulation\n",
    "date = str(datetime.datetime.strptime('2018-01-01', '%Y-%m-%d').date())\n",
    "light['converted_time'] = pd.to_datetime(date + \" \" + light.converted_time.astype(str))\n",
    "\n",
    "# do one-hot encoding for the light_conditions column\n",
    "light = pd.concat([light, pd.get_dummies(light.light_conditions)], axis=1).drop(['light_conditions', -1], axis=1)\n",
    "#srss['average_time'] = srss.apply(lambda row: find_avg_time(row.sunrise, row.sunset), axis=1)\n",
    "light.columns = ['time', 'daylight', 'lights_lit',\n",
    "                 'lights_unlit', 'no_lighting', 'unknown']\n",
    "\n",
    "# group the dataframe by hour of day\n",
    "light.groupby(pd.Grouper(key='time', freq='H')).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6ac74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in sunrise_sunset.csv as dataframe\n",
    "srss = pd.read_csv(additional_directory / 'sunrise_sunset.csv')\n",
    "\n",
    "# string formatting\n",
    "srss['sunrise'] = srss['sunrise'] + ':00'\n",
    "srss['sunset'] = srss['sunset'] + ':00'\n",
    "srss['day_length'] = srss['day_length'] + ':00'\n",
    "# create converted_date feature as np.datetime64 dtype\n",
    "srss['converted_date'] = pd.to_datetime(srss['date'])\n",
    "# drop original date column\n",
    "srss = srss.drop(['date'], axis=1)\n",
    "# convert sunrise and sunset to np.timedelta64 dtype\n",
    "srss['sunrise'] = pd.to_timedelta(srss['sunrise'])\n",
    "srss['sunset'] = pd.to_timedelta(srss['sunset'])\n",
    "\n",
    "\n",
    "def find_avg_time(first_time, second_time):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Given two times, find the average time between them\n",
    "        (t1 + t2) / 2\n",
    "    \"\"\"\n",
    "    time1_s = first_time.total_seconds()\n",
    "    time2_s = second_time.total_seconds()\n",
    "    time = (time1_s + time2_s) / 2 - 3600\n",
    "    return datetime.datetime.fromtimestamp(time).strftime(\"%H:%M\")\n",
    "    \n",
    "# create average time column using the find_avg_time function\n",
    "srss['average_time'] = srss.apply(lambda row: find_avg_time(row.sunrise, row.sunset), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ca8fe15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>day_length</th>\n",
       "      <th>converted_date</th>\n",
       "      <th>average_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 16:01:00</td>\n",
       "      <td>07:54:00</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>12:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 16:02:00</td>\n",
       "      <td>07:55:00</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>12:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 16:03:00</td>\n",
       "      <td>07:56:00</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>12:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 16:04:00</td>\n",
       "      <td>07:58:00</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>12:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 16:05:00</td>\n",
       "      <td>07:59:00</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>12:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 15:56:00</td>\n",
       "      <td>07:49:00</td>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>12:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 15:57:00</td>\n",
       "      <td>07:50:00</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>12:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 15:58:00</td>\n",
       "      <td>07:51:00</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>12:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 15:59:00</td>\n",
       "      <td>07:52:00</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>12:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>0 days 15:59:00</td>\n",
       "      <td>07:53:00</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>12:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sunrise          sunset day_length converted_date average_time\n",
       "0   0 days 08:06:00 0 days 16:01:00   07:54:00     2019-01-01        12:03\n",
       "1   0 days 08:06:00 0 days 16:02:00   07:55:00     2019-01-02        12:04\n",
       "2   0 days 08:06:00 0 days 16:03:00   07:56:00     2019-01-03        12:04\n",
       "3   0 days 08:06:00 0 days 16:04:00   07:58:00     2019-01-04        12:05\n",
       "4   0 days 08:06:00 0 days 16:05:00   07:59:00     2019-01-05        12:05\n",
       "..              ...             ...        ...            ...          ...\n",
       "360 0 days 08:06:00 0 days 15:56:00   07:49:00     2019-12-27        12:01\n",
       "361 0 days 08:06:00 0 days 15:57:00   07:50:00     2019-12-28        12:01\n",
       "362 0 days 08:06:00 0 days 15:58:00   07:51:00     2019-12-29        12:02\n",
       "363 0 days 08:06:00 0 days 15:59:00   07:52:00     2019-12-30        12:02\n",
       "364 0 days 08:06:00 0 days 15:59:00   07:53:00     2019-12-31        12:02\n",
       "\n",
       "[365 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2efb8f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accident_index', 'longitude', 'latitude', 'police_force',\n",
       "       'accident_severity', 'number_of_vehicles', 'number_of_casualties',\n",
       "       'date', 'day_of_week', 'time', 'local_authority_(district)',\n",
       "       'local_authority_(highway)', '1st_road_class', '1st_road_number',\n",
       "       'road_type', 'speed_limit', 'junction_detail', 'junction_control',\n",
       "       '2nd_road_class', '2nd_road_number',\n",
       "       'pedestrian_crossing-human_control',\n",
       "       'pedestrian_crossing-physical_facilities', 'light_conditions',\n",
       "       'weather_conditions', 'road_surface_conditions',\n",
       "       'special_conditions_at_site', 'carriageway_hazards',\n",
       "       'urban_or_rural_area', 'did_police_officer_attend_scene_of_accident',\n",
       "       'lsoa_of_accident_location', 'district', 'converted_date',\n",
       "       'converted_time', 'sunrise', 'sunset', 'day_length', 'average_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns which are not needed\n",
    "#srss = srss.drop(['sunrise', 'sunset', 'day_length'], axis=1)\n",
    "# merge useful columns of srss to accidents dataframe on converted_date column\n",
    "accidents = pd.merge(accidents, srss, on=['converted_date'])\n",
    "\n",
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7985b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accident_index', 'longitude', 'latitude', 'police_force',\n",
       "       'accident_severity', 'number_of_vehicles', 'number_of_casualties',\n",
       "       'date', 'day_of_week', 'time', 'local_authority_(district)',\n",
       "       'local_authority_(highway)', '1st_road_class', '1st_road_number',\n",
       "       'road_type', 'speed_limit', 'junction_detail', 'junction_control',\n",
       "       '2nd_road_class', '2nd_road_number',\n",
       "       'pedestrian_crossing-human_control',\n",
       "       'pedestrian_crossing-physical_facilities', 'light_conditions',\n",
       "       'weather_conditions', 'road_surface_conditions',\n",
       "       'special_conditions_at_site', 'carriageway_hazards',\n",
       "       'urban_or_rural_area', 'did_police_officer_attend_scene_of_accident',\n",
       "       'lsoa_of_accident_location', 'district', 'converted_date',\n",
       "       'converted_time', 'sunrise', 'sunset', 'day_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask for values with null values in converted_time column\n",
    "missing_time_mask = accidents[\"converted_time\"].isnull()\n",
    "\n",
    "# impute missing times with average time \n",
    "accidents.loc[missing_time_mask, 'converted_time'] = accidents.loc[missing_time_mask, 'average_time']\n",
    "\n",
    "accidents = accidents.drop(['average_time'], axis=1)\n",
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0bc2c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2019-02-18 17:50:00\n",
       "1        2019-02-18 18:50:00\n",
       "2        2019-02-18 23:00:00\n",
       "3        2019-02-18 02:00:00\n",
       "4        2019-02-18 08:00:00\n",
       "                 ...        \n",
       "117531   2019-04-21 10:11:00\n",
       "117532   2019-04-21 11:10:00\n",
       "117533   2019-04-21 08:10:00\n",
       "117534   2019-04-21 16:20:00\n",
       "117535   2019-04-21 12:45:00\n",
       "Name: datetime, Length: 117536, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a single 'datetime' feature in ISO 8601 format\n",
    "# using numpy.datetime64 object\n",
    "\n",
    "accidents['datetime'] = pd.to_datetime(accidents['converted_date'].astype(str) + \" \" + accidents['converted_time'].astype(str),\n",
    "               format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# dropping the original date and time columns\n",
    "accidents = accidents.drop(['date', 'time'], axis=1)\n",
    "accidents['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6381351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accident_index                                    0\n",
       "longitude                                         0\n",
       "latitude                                          0\n",
       "police_force                                      0\n",
       "accident_severity                                 0\n",
       "number_of_vehicles                                0\n",
       "number_of_casualties                              0\n",
       "day_of_week                                       0\n",
       "local_authority_(district)                        0\n",
       "local_authority_(highway)                         0\n",
       "1st_road_class                                    0\n",
       "1st_road_number                                   0\n",
       "road_type                                         0\n",
       "speed_limit                                       0\n",
       "junction_detail                                   0\n",
       "junction_control                                  0\n",
       "2nd_road_class                                    0\n",
       "2nd_road_number                                   0\n",
       "pedestrian_crossing-human_control                 0\n",
       "pedestrian_crossing-physical_facilities           0\n",
       "light_conditions                                  0\n",
       "weather_conditions                                0\n",
       "road_surface_conditions                           0\n",
       "special_conditions_at_site                        0\n",
       "carriageway_hazards                               0\n",
       "urban_or_rural_area                               0\n",
       "did_police_officer_attend_scene_of_accident       0\n",
       "lsoa_of_accident_location                      5714\n",
       "district                                          0\n",
       "converted_date                                    0\n",
       "converted_time                                    0\n",
       "sunrise                                           0\n",
       "sunset                                            0\n",
       "day_length                                        0\n",
       "datetime                                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time column is now cleaned\n",
    "accidents.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1de74127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>decimal_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-18 17:50:00</td>\n",
       "      <td>17.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-18 18:50:00</td>\n",
       "      <td>18.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-18 23:00:00</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-18 02:00:00</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-18 08:00:00</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  decimal_time\n",
       "0 2019-02-18 17:50:00     17.833333\n",
       "1 2019-02-18 18:50:00     18.833333\n",
       "2 2019-02-18 23:00:00     23.000000\n",
       "3 2019-02-18 02:00:00      2.000000\n",
       "4 2019-02-18 08:00:00      8.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a decimal time column using the time component of 'converted_time'\n",
    "def convert_to_decimal(df, new_col, original_col='datetime',):\n",
    "    \"\"\"Convert datetime.time value to decimal\"\"\"\n",
    "    df[new_col] = df[original_col].dt.hour + df[original_col].dt.minute / 60\n",
    "    \n",
    "# create decimal_time column\n",
    "convert_to_decimal(accidents, 'decimal_time', 'datetime')\n",
    "\n",
    "accidents.loc[:, ['datetime', 'decimal_time']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61702dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59099</th>\n",
       "      <td>2019-07-15 17:50:00</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82171</th>\n",
       "      <td>2019-09-25 14:54:00</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>2019-03-07 15:30:00</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77820</th>\n",
       "      <td>2019-09-13 09:00:00</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81286</th>\n",
       "      <td>2019-09-23 16:00:00</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94124</th>\n",
       "      <td>2019-10-31 18:35:00</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40214</th>\n",
       "      <td>2019-05-17 16:18:00</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97164</th>\n",
       "      <td>2019-11-09 01:43:00</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40769</th>\n",
       "      <td>2019-05-20 07:50:00</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43032</th>\n",
       "      <td>2019-05-27 18:00:00</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime  day_of_year\n",
       "59099 2019-07-15 17:50:00          196\n",
       "82171 2019-09-25 14:54:00          268\n",
       "19660 2019-03-07 15:30:00           66\n",
       "77820 2019-09-13 09:00:00          256\n",
       "81286 2019-09-23 16:00:00          266\n",
       "94124 2019-10-31 18:35:00          304\n",
       "40214 2019-05-17 16:18:00          137\n",
       "97164 2019-11-09 01:43:00          313\n",
       "40769 2019-05-20 07:50:00          140\n",
       "43032 2019-05-27 18:00:00          147"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_day_of_year(datetime_val):\n",
    "    \"\"\"Return the day of the year for a given datetime.date value\"\"\"\n",
    "    return datetime_val.dayofyear\n",
    "\n",
    "accidents['day_of_year'] = accidents['datetime'].apply(to_day_of_year)\n",
    "accidents['day_of_year'] = accidents['day_of_year'].fillna(-10)\n",
    "accidents['day_of_year'] = accidents['day_of_year'].astype('int32')\n",
    "\n",
    "# 10 randomly sampled columns\n",
    "accidents.loc[:, ['datetime', 'day_of_year']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f785e4a4",
   "metadata": {},
   "source": [
    "## Exporting cleaned dataframe\n",
    "\n",
    "The cleaned dataframe is exported in serialised pickle format so that it can be read into other notebooks without losing datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5618edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save serialised dataframe for loading in other notebooks\n",
    "accidents.to_pickle(additional_data_dir / 'accidents_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eabbcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
